# ğŸ¯ Resume Parsing & Data Extraction System
**It's live on Render**

https://resume-parser-system-ivfd.onrender.com/

A web-based intelligent resume parsing application that automates manual data entry by extracting structured information from resumes and storing it into Excel.

Designed for university/placement-cell level automation to reduce manual workload of teachers and administrators.

---

# ğŸ“Œ Project Overview

This system allows users to upload resumes (PDF/DOCX/Image) and automatically extracts structured information such as:

* Name
* Email
* Phone Number
* Skills
* Education
* Certifications
* Experience
* Publications
* Awards

The extracted data is stored in Excel and displayed in a clean web interface.

The goal is to eliminate manual resume reading and Excel entry work.

---

# ğŸ§  Key Features

## ğŸ“‚ Resume Upload

* Supports **PDF, DOCX, PNG, JPG**
* File type validation (frontend + backend)
* Secure upload handling

## ğŸ” Intelligent Data Extraction

Rule-based extraction system for:

* Name detection
* Email extraction
* Phone number extraction
* Skills extraction
* Education extraction (score-validated)
* Certification extraction (section aware)

## ğŸ“Š Excel-Based Storage

* No database required
* All parsed data stored in Excel
* Easy portability
* Download anytime

## ğŸ–¥ï¸ Interactive UI

* Clean table display
* Modal popup for details
* View education/certifications
* Delete row
* Undo delete
* Reset all data
* Download Excel

## ğŸ§© Additional Sections Extracted

* Experience
* Publications
* Awards/Achievements

---

# ğŸ—ï¸ Project Architecture

The system follows modular architecture with clear separation of logic.

```
Resume Parser/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                # Flask app entry
â”‚   â”œâ”€â”€ parser/
â”‚   â”‚   â”œâ”€â”€ extractor.py       # Data extraction logic
â”‚   â”‚   â”œâ”€â”€ pdf_parser.py      # PDF text extraction
â”‚   â”‚   â”œâ”€â”€ docx_parser.py     # DOCX text extraction
â”‚   â”‚   â”œâ”€â”€ image_parser.py    # Image OCR extraction
â”‚   â”‚   â””â”€â”€ keywords.py        # Keyword datasets
â”‚   â”‚
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ excel_service.py   # Excel operations
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html             # Frontend UI
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css
â”‚   â”œâ”€â”€ script.js
â”‚   â””â”€â”€ favicon.png
â”‚
â”œâ”€â”€ uploads/                   # Uploaded resumes
â”œâ”€â”€ output/
â”‚   â””â”€â”€ resume_data.xlsx       # Excel storage
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Procfile                   # Render deployment
â””â”€â”€ README.md
```

---

# âš™ï¸ How It Works

1. User uploads resume
2. System extracts text from file
3. Extractor processes structured data
4. Data stored in Excel
5. Displayed in UI table
6. User can view/delete/download/reset

---

# ğŸš€ Installation & Setup (Local)

## 1ï¸âƒ£ Clone Repository

```
git clone https://github.com/YOUR_USERNAME/resume-parser.git
cd resume-parser
```

## 2ï¸âƒ£ Create Virtual Environment

```
python -m venv venv
venv\Scripts\activate   (Windows)
```

## 3ï¸âƒ£ Install Requirements

```
pip install -r requirements.txt
```

## 4ï¸âƒ£ Run Application

```
python -m app.main
```

Open browser:

```
http://127.0.0.1:5000
```

---

# ğŸŒ Live Deployment (Render)

This project is deployed using **Render free hosting**.

### Deployment Steps

1. Push code to GitHub
2. Create new Web Service on Render
3. Add build & start commands:

**Build**

```
pip install -r requirements.txt
```

**Start**

```
gunicorn app.main:app
```

4. Deploy and get live URL

---

# ğŸ“¦ Requirements

```
flask
gunicorn
pandas
pdfplumber
python-docx
openpyxl
pillow
```

---

# ğŸ§  Extraction Logic Used

## âœ” Rule-Based Extraction

* Regex for email & phone
* Keyword mapping for skills
* Score-validated education detection
* Section-aware certification detection

## âœ” Accuracy Improvements

* Block-based certification extraction
* Education validation with score matching
* Section detection logic
* Clean normalization

---

# ğŸ“Š Why Excel Instead of Database?

* Lightweight deployment
* Easy portability
* No setup required
* Suitable for university-level usage
* Can upgrade to DB in future

---

# ğŸ”’ Privacy & Security

* No external API required
* Local parsing
* No data sharing
* Suitable for confidential resumes

---

# ğŸ“ˆ Future Enhancements (Tier-2 â†’ Tier-3)

* NLP-based section detection (spaCy)
* AI-assisted experience extraction
* Database integration (MySQL/PostgreSQL)
* Admin dashboard
* Multi-user support
* Bulk resume upload
* Analytics dashboard

---

# ğŸ¯ Use Cases

* University placement cells
* HR resume screening
* Internship filtering
* Recruitment automation
* Academic project submission analysis

---

# ğŸ Project Status

âœ” Fully working
âœ” End-to-end functional
âœ” Hosted live
âœ” Demo ready
âœ” Scalable architecture
âœ” Production-ready for small scale

---

# ğŸ‘¨â€ğŸ’» Author

**Jignesh Thacker**
AI/ML & Python Developer

This project was built to automate manual resume data entry and demonstrate scalable resume parsing architecture using Python & Flask.

# Output ScreenShot
<img width="1432" height="500" alt="image" src="https://github.com/user-attachments/assets/cd8b4891-5a44-4b84-afb8-d4f21fa3c0f4" />
<img width="1437" height="735" alt="image" src="https://github.com/user-attachments/assets/5dd95b50-254e-4007-9197-d9f07f48c7c6" />





---

# â­ If you like this project

Give it a star on GitHub and share feedback!
